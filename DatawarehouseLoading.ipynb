{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f1944c8",
   "metadata": {},
   "source": [
    "# Libraries Imports \n",
    "## Setting Up DB onnections and destinations files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7553b0cd",
   "metadata": {},
   "source": [
    "#creating the tables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3179ec02",
   "metadata": {},
   "source": [
    "## Extracting the dimensions , selecting only a limited number of rows due to the large size of the data and loading into the DW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be90e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "from sqlalchemy import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#stagingDb= 'binatbit' and the datawarhouse = 'dw_v3'\n",
    "# had to delete the staging db due to the disk usage and moved to working on the main db direclty \n",
    "# svr_name and db_name are the variable needed in the odbc connection : \n",
    "svr_name = 'ANAS\\YORUDEV'\n",
    "db_name= 'dw_v3'\n",
    "\n",
    "#Connect to SQL Server\n",
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=ANAS\\YORUDEV;'\n",
    "                      'Database=dw_v3;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "cursor = conn.cursor()\n",
    "eng = create_engine(\"mssql+pyodbc://\"+svr_name+\"/\"+db_name+\"?driver=SQL+Server\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e439a5cc",
   "metadata": {},
   "source": [
    "## Loading the data to the DW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e12e0480",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding records to the database is done successfully\n"
     ]
    }
   ],
   "source": [
    "# creating a list where i give the name of the file that i put in a separate file on my desktop or anywhere else :\n",
    "listData = ['roadTrafficDeaths.csv','pharmacists.csv','alcoholSubstanceAbuse.csv','medicalDoctors.csv','crudeSuicideRates.csv']\n",
    "# we iterate over the list and apply the read csv methode to each file representing the dimensions \n",
    "# then load it to the sql database with the to sql method\n",
    "for i in listData:\n",
    "    \n",
    "    myData = pd.read_csv(f\"C:/Users/Mars/Desktop/ProjetBI/projectV3/{i}\",sep=';|,',engine='python')\n",
    "    #z.to_sql(i.split(\".\")[0].capitalize(),eng, if_exists='replace',index=False)\n",
    "    \n",
    "    \n",
    "print(\"Adding records to the database is done successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c131ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# maybe will try the visualization here\n",
    "\n",
    "#sql_query = '''\n",
    "#SELECT TOP 1000 * \n",
    "#FROM \"World Health Facts\"\n",
    "#'''\n",
    "#pd.read_sql(sql_query,conn)\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba0bfde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
